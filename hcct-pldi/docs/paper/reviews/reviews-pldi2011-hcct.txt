===========================================================================
                          PLDI 2011 Review #149A
                  Updated Friday 7 Jan 2011 9:07:56pm CST
---------------------------------------------------------------------------
          Paper #149: Mining Hot Calling Contexts in Small Space
---------------------------------------------------------------------------

                      Overall merit: 4. Accept
                 Reviewer expertise: 2. Some familiarity

                         ===== Paper summary =====

This paper proposes Hot Calling Context Tree (HCCT), a data structure for finding hot contexts with low runtime overhead. A comprehensive algorithmic and experimental evaluation is given.

            ===== Area of the paper (List all that apply) =====

7,14

              ===== Evaluation and comments for author =====

I enjoyed reading this paper. I think it combines some good insight about how to integrated frequent item mining algorithms in the context of calling context trees to produce HCCTs. The balance of theory and practice in this paper is great to see. The evaluation is thorough and the numbers are encouraging. I feel that this approach has the poetential benefit of enabling some previously impossible applications, which would otherwise be too constly. However, I think the paper could benefit from more of a discussion of some of the applications in addition to the technqiues.

Minor comments:
	- figure 1 and 6 are very hard to read in B&W. Please either reduce the number of benchmarks you show at once or make the lines more distict

Other comments below:
- Figures 1 and 6 is very hard to read, especially in B&W. Please separate the benchmars into groups or only show a few representative ones
- Given that you are experimenting with long-running applications, it would be instructive to 
        - Describe the workload in more detail and
	- You use some long-running applications. What kind of workloads did you use for each?
	- Can you comment on how the runtime overhead (both time and space) varies as the applications keep running. Will the overhead become virtually 0 for a long-running application like a web server or one of the office programs you're experimenting with? Does that enable you to have always-on monitoring for a small initial cost?

===========================================================================
                          PLDI 2011 Review #149B
                 Updated Saturday 8 Jan 2011 1:47:13pm CST
---------------------------------------------------------------------------
          Paper #149: Mining Hot Calling Contexts in Small Space
---------------------------------------------------------------------------

                      Overall merit: 5. Strong accept
                 Reviewer expertise: 3. Knowledgeable

                         ===== Paper summary =====

Shows how to use data mining techniques to compute calling context trees that primarily contain the hot routines.

            ===== Area of the paper (List all that apply) =====

7, 14

              ===== Evaluation and comments for author =====

Great paper! The insightful combination of modern techniques from data mining with CCT yields an extremely practical algorithm. The paper is very clearly written and does a fine job of presenting context and exploring the alternatives.

My one complaint is that I would like to see actual run-time overheads, not speedups over an unknown baseline.

===========================================================================
                          PLDI 2011 Review #149C
                 Updated Monday 10 Jan 2011 11:14:26am CST
---------------------------------------------------------------------------
          Paper #149: Mining Hot Calling Contexts in Small Space
---------------------------------------------------------------------------

                      Overall merit: 4. Accept
                 Reviewer expertise: 3. Knowledgeable

                         ===== Paper summary =====

The paper proposes a technique to construct hot calling-context tree (HCCT) to improve the space efficiency of full calling-context tree (CCT) without sacrificing significant accuracy. The basic idea is to maintain CCTs for only hot calling contexts. And they use well known streaming algorithms for the heavy hitters problems to compute hot calling context and to construct HCCT in a space efficient manner. The system is evaluated on several large linux applications and has demonstrated significant space saving compared to full CCT.

            ===== Area of the paper (List all that apply) =====

17, 21: profiling techniques

              ===== Evaluation and comments for author =====

The crux of the paper is on the formalization of hot calling context selection into a classic heavy-hitter problem.  Hotness selection is a classical topic in dynamic optimizations, but has mostly been approached by heuristics and intuition. This paper did an exceptional job in using theories of heavy-hitter problems to elucidate various aspects of HCCT. Although the paper used mostly well known algorithms, I think the application of classic algorithms into a new problem domain is itself a significant contribution. Overall, this is a really nice work with both a solid theoretical foundation, good insights, and demonstrated effectiveness. I really enjoyed reading the paper.

===========================================================================
                          PLDI 2011 Review #149D
                 Updated Monday 10 Jan 2011 9:06:56pm CST
---------------------------------------------------------------------------
          Paper #149: Mining Hot Calling Contexts in Small Space
---------------------------------------------------------------------------

                      Overall merit: 4. Accept
                 Reviewer expertise: 4. Expert

                         ===== Paper summary =====

Profiling hot calling contexts (and potentially associating information such as performance counters with calling contexts) can direct optimizations and improve program understanding in ways that call graph profiling cannot.  Unfortunately, even medium-sized programs may execute 10^7 or more distinct contexts, so constructing and maintaining each thread's position in the calling context tree (CCT) yields high space overhead and poor locality.  Sampling trades accuracy for time and space, but it will still build large CCTs with many cold contexts.  This paper uses data streaming techniques to construct a hot CCT (HCCT) that maintains hot nodes and their ancestors.  Existing data streaming techniques enable the HCCT to contain all hot nodes and few cold codes, with low space overhead; the paper's evaluation on real programs confirms these theoretical benefits.

            ===== Area of the paper (List all that apply) =====

7, 13, 16

              ===== Evaluation and comments for author =====

Applying data streaming techniques to program profiling is a good idea, particularly for calling contexts, since there are many distinct calling contexts but most are cold.  The paper is explained well (Figure 3 and its explanation are really helpful), and the evaluation is thorough and detailed.  

The paper argues that its approach works even better with sampling than full instrumentation, which seems believable.  However, the paper lacks results (except for space and time overheads) showing how much the approach helps sampling, i.e., sampling alone vs. sampling plus data streaming techniques.  Instead the paper focuses on full instrumentation, i.e., full instrumentation alone vs. full instrumentation plus data streaming techniques.  However, it seems important to incorporate sampling, not just to show how much the approach helps sampling, but also to show that the paper's approach is superior to sampling alone -- is the paper even arguing that its approach applied to full instrumentation is a good idea (i.e., better than sampling alone), or must the paper's approach be applied to sampling to be useful?  A key question is, why isn't sampling good enough, especially the technique from Zhuang et al. 2006?  Is it the space overhead or the accuracy or both?  The paper's approach can certainly improve these factors (by how much?), but the paper also needs to show how Zhuang et al.'s space overhead and/or accuracy aren't good enough to be used in practice.

Related to that, the paper's argument for the advantage of bursty vs. random sampling isn't backed up with evidence.

Section 1: "edges edges"

